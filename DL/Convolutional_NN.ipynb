{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b9a6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [7]] (2,)\n",
      "[[2 5]] (2,)\n",
      "[[12 30]\n",
      " [14 35]]\n",
      "[[12 30]\n",
      " [14 35]]\n",
      "[[[ 2  3]\n",
      "  [ 2  3]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 8 10]\n",
      "  [ 8 10]\n",
      "  [ 8 10]]]\n",
      "[[2 3]\n",
      " [2 3]\n",
      " [2 3]]\n",
      "changed5\n"
     ]
    }
   ],
   "source": [
    "%run modules.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979ffe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "X_train = mnist.train_images()[10000:,:,:].reshape(50000,1,28,28)\n",
    "X_val = mnist.train_images()[:10000,:,:].reshape(10000,1,28,28)\n",
    "X_test = mnist.test_images().reshape(10000,1,28,28)\n",
    "y_test = mnist.test_labels()\n",
    "y_train = mnist.train_labels()[10000:]\n",
    "y_val = mnist.train_labels()[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a2f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train = enc.fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_val = enc.transform(y_val.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427efd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch generator\n",
    "def get_batches(dataset, batch_size):\n",
    "    X, Y = dataset\n",
    "    n_samples = X.shape[0]\n",
    "        \n",
    "    # Shuffle at the start of epoch\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    for start in range(0, n_samples, batch_size):\n",
    "        end = min(start + batch_size, n_samples)\n",
    "        \n",
    "        batch_idx = indices[start:end]\n",
    "    \n",
    "        yield X[batch_idx], Y[batch_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "920f6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = Sequential()\n",
    "seq.add(Conv2d(1, 16, 5))\n",
    "seq.add(ReLU())\n",
    "seq.add(MaxPool2d(2))\n",
    "seq.add(Conv2d(16, 32, 5))\n",
    "seq.add(ReLU())\n",
    "seq.add(MaxPool2d(2))\n",
    "seq.add(Flatten())\n",
    "seq.add(Linear(32*7*7, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d347ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = ClassNLLCriterion()\n",
    "optimizer_config = {'learning_rate' : 5e-2, 'momentum': 0.9}\n",
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20b0893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward\n",
      "outp_shape max (1000, 16, 14, 14)\n",
      "outp_shape max (1000, 32, 7, 7)\n",
      "Backward\n",
      "outp_shape max (1000, 16, 14, 14)\n",
      "outp_shape max (1000, 32, 7, 7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in1 and in2 should have the same dimensionality",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBackward\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m dp \u001b[38;5;241m=\u001b[39m criterion\u001b[38;5;241m.\u001b[39mbackward(predictions, y_batch)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdating weights\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/tmp/ipykernel_273649/3883017435.py:66\u001b[0m, in \u001b[0;36mSequential.backward\u001b[0;34m(self, input, gradOutput)\u001b[0m\n\u001b[1;32m     63\u001b[0m     y\u001b[38;5;241m.\u001b[39mappend(module\u001b[38;5;241m.\u001b[39mforward(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module, y_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules), \u001b[38;5;28mreversed\u001b[39m(y[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradInput \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_i\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradInput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradInput\n",
      "File \u001b[0;32m/tmp/ipykernel_273649/1342133365.py:35\u001b[0m, in \u001b[0;36mModule.backward\u001b[0;34m(self, input, gradOutput)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03mPerforms a backpropagation step through the module, with respect to the given input.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m - computing a gradient w.r.t. parameters (to update parameters while optimizing).\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdateGradInput(\u001b[38;5;28minput\u001b[39m, gradOutput)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccGradParameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradOutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradInput\n",
      "File \u001b[0;32m/tmp/ipykernel_273649/618188406.py:67\u001b[0m, in \u001b[0;36mConv2d.accGradParameters\u001b[0;34m(self, input, gradOutput)\u001b[0m\n\u001b[1;32m     65\u001b[0m     sample \u001b[38;5;241m=\u001b[39m padded_input[i]\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels):\n\u001b[0;32m---> 67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradW \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradOutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m=\u001b[39m gradOutput[c]\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/scipy/signal/signaltools.py:228\u001b[0m, in \u001b[0;36mcorrelate\u001b[0;34m(in1, in2, mode, method)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m in1 \u001b[38;5;241m*\u001b[39m in2\u001b[38;5;241m.\u001b[39mconj()\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m in1\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m in2\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min1 and in2 should have the same dimensionality\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# Don't use _valfrommode, since correlate should not accept numeric modes\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: in1 and in2 should have the same dimensionality"
     ]
    }
   ],
   "source": [
    "n_epoch = 15\n",
    "batch_size = 1000\n",
    "\n",
    "for i in range(n_epoch):\n",
    "    for x_batch, y_batch in get_batches((X_train, y_train), batch_size):\n",
    "        \n",
    "        seq.zeroGradParameters()\n",
    "        \n",
    "        # Forward\n",
    "        print('Forward')\n",
    "        predictions = seq.forward(x_batch)\n",
    "        loss = criterion.forward(predictions, y_batch)\n",
    "    \n",
    "        # Backward\n",
    "        print('Backward')\n",
    "        dp = criterion.backward(predictions, y_batch)\n",
    "        seq.backward(x_batch, dp)\n",
    "        \n",
    "        \n",
    "        # Update weights\n",
    "        print('Updating weights')\n",
    "        sgd_momentum(seq.getParameters(),  seq.getGradParameters(), optimizer_config, optimizer_state)  \n",
    "        loss_history.append(loss)\n",
    "        \n",
    "\n",
    "    # Visualize\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "        \n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"#iteration\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(np.log(loss_history_ReLu), label='ReLU')\n",
    "    plt.plot(np.log(loss_history_LeakyReLu), label = 'LeakyReLU')\n",
    "    plt.plot(np.log(loss_history_ELU), label = 'ELU')\n",
    "    plt.plot(np.log(loss_history_SoftPlus), label = 'SoftPlus')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print('Current loss ReLU: %f' % loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
