{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-06T07:35:19.454024Z",
     "iopub.status.busy": "2022-05-06T07:35:19.453712Z",
     "iopub.status.idle": "2022-05-06T07:35:19.459964Z",
     "shell.execute_reply": "2022-05-06T07:35:19.458725Z",
     "shell.execute_reply.started": "2022-05-06T07:35:19.453984Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:44:09.388572Z",
     "iopub.status.busy": "2022-05-06T06:44:09.388227Z",
     "iopub.status.idle": "2022-05-06T06:44:09.472196Z",
     "shell.execute_reply": "2022-05-06T06:44:09.470513Z",
     "shell.execute_reply.started": "2022-05-06T06:44:09.388522Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('CUDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:44:10.362315Z",
     "iopub.status.busy": "2022-05-06T06:44:10.361361Z",
     "iopub.status.idle": "2022-05-06T06:44:10.411877Z",
     "shell.execute_reply": "2022-05-06T06:44:10.410799Z",
     "shell.execute_reply.started": "2022-05-06T06:44:10.36227Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/tales-dataset/train.txt'\n",
    "input_text = open(path, 'r', encoding='utf-8').read()\n",
    "input_text = input_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:44:10.943092Z",
     "iopub.status.busy": "2022-05-06T06:44:10.942723Z",
     "iopub.status.idle": "2022-05-06T06:44:10.952987Z",
     "shell.execute_reply": "2022-05-06T06:44:10.951839Z",
     "shell.execute_reply.started": "2022-05-06T06:44:10.94305Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, dataset):\n",
    "        super(Model, self).__init__()\n",
    "        self.lstm_size = 300\n",
    "        self.embedding_dim = 200\n",
    "        self.num_layers = 3\n",
    "        n_vocab = len(dataset.uniq_words)\n",
    "        self.embedding = nn.Embedding(num_embeddings=n_vocab, embedding_dim=self.embedding_dim,)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embedding_dim,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.fc(output)\n",
    "        return logits, state\n",
    "    def init_state(self, sequence_length):\n",
    "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
    "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:44:11.467069Z",
     "iopub.status.busy": "2022-05-06T06:44:11.466754Z",
     "iopub.status.idle": "2022-05-06T06:44:11.479603Z",
     "shell.execute_reply": "2022-05-06T06:44:11.478416Z",
     "shell.execute_reply.started": "2022-05-06T06:44:11.467036Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text, seq_len):\n",
    "        self.seq_len = seq_len\n",
    "        self.text = text\n",
    "        self.words = self.load_words()\n",
    "        self.uniq_words = self.get_uniq_words()\n",
    "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
    "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
    "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
    "    def load_words(self):\n",
    "        return self.text.split(' ')\n",
    "    def get_uniq_words(self):\n",
    "        word_counts = Counter(self.words)\n",
    "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    def __len__(self):\n",
    "        return len(self.words_indexes) - self.seq_len\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.words_indexes[index:index+self.seq_len]),\n",
    "            torch.tensor(self.words_indexes[index+1:index+self.seq_len+1]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:45:06.735024Z",
     "iopub.status.busy": "2022-05-06T06:45:06.734721Z",
     "iopub.status.idle": "2022-05-06T06:45:06.746689Z",
     "shell.execute_reply": "2022-05-06T06:45:06.745531Z",
     "shell.execute_reply.started": "2022-05-06T06:45:06.734991Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_len = 5\n",
    "max_epochs = 15\n",
    "def train(dataset, model, device = device):\n",
    "    model.train()\n",
    "    dataloader = DataLoader(dataset, batch_size=2048)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    for epoch in range(max_epochs):\n",
    "        state_h, state_c = model.init_state(seq_len)\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred, (state_h, state_c) = model(x.to(device), (state_h.to(device), state_c.to(device)))\n",
    "            loss = criterion(y_pred.transpose(1, 2), y.to(device))\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T08:21:56.24817Z",
     "iopub.status.busy": "2022-05-06T08:21:56.247434Z",
     "iopub.status.idle": "2022-05-06T08:21:56.257183Z",
     "shell.execute_reply": "2022-05-06T08:21:56.255953Z",
     "shell.execute_reply.started": "2022-05-06T08:21:56.248126Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=300, temperature=1.0):\n",
    "    model.eval()\n",
    "    words = text.split(' ')\n",
    "    state_h, state_c = model.init_state(len(words))\n",
    "    for i in range(0, next_words):\n",
    "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
    "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "        p = torch.nn.functional.softmax(last_word_logits/temperature, dim=0).detach().numpy()\n",
    "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
    "        words.append(dataset.index_to_word[word_index])\n",
    "        text= text + ' ' + dataset.index_to_word[word_index]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:45:08.248026Z",
     "iopub.status.busy": "2022-05-06T06:45:08.247299Z",
     "iopub.status.idle": "2022-05-06T07:25:25.836566Z",
     "shell.execute_reply": "2022-05-06T07:25:25.835524Z",
     "shell.execute_reply.started": "2022-05-06T06:45:08.247989Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(input_text, seq_len)\n",
    "model = Model(dataset)\n",
    "model.to(device)\n",
    "train(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:25:25.839791Z",
     "iopub.status.busy": "2022-05-06T07:25:25.838782Z",
     "iopub.status.idle": "2022-05-06T07:25:25.846596Z",
     "shell.execute_reply": "2022-05-06T07:25:25.845439Z",
     "shell.execute_reply.started": "2022-05-06T07:25:25.839746Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(path, model):\n",
    "    state = {'state_dict': model.state_dict()}\n",
    "    torch.save(state, path)\n",
    "    print('model saved to %s' % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T08:24:59.200784Z",
     "iopub.status.busy": "2022-05-06T08:24:59.200437Z",
     "iopub.status.idle": "2022-05-06T08:24:59.362232Z",
     "shell.execute_reply": "2022-05-06T08:24:59.361115Z",
     "shell.execute_reply.started": "2022-05-06T08:24:59.20075Z"
    }
   },
   "outputs": [],
   "source": [
    "save_checkpoint(\"LSTM30epoch.pth\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:35:29.573791Z",
     "iopub.status.busy": "2022-05-06T07:35:29.573455Z",
     "iopub.status.idle": "2022-05-06T07:35:30.434498Z",
     "shell.execute_reply": "2022-05-06T07:35:30.433196Z",
     "shell.execute_reply.started": "2022-05-06T07:35:29.573752Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "print(predict(dataset, model, text='once upon a', temperature = 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:35:56.690822Z",
     "iopub.status.busy": "2022-05-06T07:35:56.690395Z",
     "iopub.status.idle": "2022-05-06T07:35:57.533378Z",
     "shell.execute_reply": "2022-05-06T07:35:57.532209Z",
     "shell.execute_reply.started": "2022-05-06T07:35:56.690792Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict(dataset, model, text='once upon a', temperature = 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:37:03.055894Z",
     "iopub.status.busy": "2022-05-06T07:37:03.055551Z",
     "iopub.status.idle": "2022-05-06T08:17:31.353698Z",
     "shell.execute_reply": "2022-05-06T08:17:31.352749Z",
     "shell.execute_reply.started": "2022-05-06T07:37:03.055848Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "train(dataset, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T08:18:40.238926Z",
     "iopub.status.busy": "2022-05-06T08:18:40.238628Z",
     "iopub.status.idle": "2022-05-06T08:18:41.500596Z",
     "shell.execute_reply": "2022-05-06T08:18:41.499515Z",
     "shell.execute_reply.started": "2022-05-06T08:18:40.238893Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "print(predict(dataset, model, text='once upon a', temperature = 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T08:19:24.71137Z",
     "iopub.status.busy": "2022-05-06T08:19:24.711024Z",
     "iopub.status.idle": "2022-05-06T08:19:25.865131Z",
     "shell.execute_reply": "2022-05-06T08:19:25.864084Z",
     "shell.execute_reply.started": "2022-05-06T08:19:24.71134Z"
    }
   },
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "print(predict(dataset, model, text='once upon a', temperature = 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T08:23:47.657219Z",
     "iopub.status.busy": "2022-05-06T08:23:47.656895Z",
     "iopub.status.idle": "2022-05-06T08:23:50.682992Z",
     "shell.execute_reply": "2022-05-06T08:23:50.680616Z",
     "shell.execute_reply.started": "2022-05-06T08:23:47.65718Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict(dataset, model, text='the young man', temperature = 0.8).replace(\"<| end of text |>\", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
